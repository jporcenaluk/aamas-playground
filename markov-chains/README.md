# Markov Chains

Markov Chains are the grandpappy of environments in Agents & Multi-Agent systems. In a way, nearly all environments can be considered as a more-complex version of the Markov Chain.

A Markov Decision Process (MDP) is an _extension_ of the concept of a Markov Chain, and that leads to Partially-Observable Markov Decision Processes (POMDP) and the many branches from there including Decentralised POMDPs (Dec-POMDP).

As you can see, many roads lead from the source that is Markov Chains so understanding them deeply leads to better understanding at higher abstractions.

## Resources

* ["Introducing Markov Chains" by Harvard Online (Video)](https://www.youtube.com/watch?v=JHwyHIz6a8A) - an excellent introduction
* ["Markov Chains" by Normalized Nerd (Video)](https://www.youtube.com/playlist?list=PLM8wYQRetTxBkdvBtz-gw8b9lcVkdXQKV) - if you want to dive deeper
* ["Markov Chains in Python: Beginner Tutorial" by DataCamp (Tutorial)](https://www.datacamp.com/tutorial/markov-chains-python-tutorial) - apply that knowledge to a tutorial!

# Stats

* born: 1906
* parent: [Andrey Markov](https://en.wikipedia.org/wiki/Markov_chain#history)